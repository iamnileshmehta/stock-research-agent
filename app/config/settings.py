LLM_PROVIDER = "gemini"   # "gemini", "openai" (future)
model = "gemini-2.5-flash"